name: Local LLM PR Summary

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: read
  pull-requests: write

jobs:
  generate-summary:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/ggml-org/llama.cpp:full

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install build dependencies
        run: |
          apt-get update && apt-get install -y cmake build-essential git libcurl4-openssl-dev

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggml-org/llama.cpp.git /llama.cpp

      - name: Build llama.cpp
        run: |
          cd /llama.cpp
          cmake -B build -DLLAMA_BUILD_EXAMPLES=ON
          cmake --build build --config Release -j$(nproc)

      - name: Download model (Mistral 7B)
        run: |
          mkdir -p /models/
          curl -L https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf \
            -o /models/mistral.gguf

      - name: Locate `llama-cli` binary
        id: locate-cli
        run: |
          echo "Listing all executables in build dir..."
          find /llama.cpp/build -type f -executable -exec ls -l {} \;

          CLI_PATH=$(find /llama.cpp/build -type f -name llama-cli -executable | head -n 1)
          echo "Found llama-cli binary at: $CLI_PATH"
          if [ -z "$CLI_PATH" ]; then
            echo "‚ùå llama-cli binary not found"
            exit 1
          fi
          echo "main-path=$CLI_PATH" >> $GITHUB_OUTPUT

      - name: Generate diff summary
        id: llm-summary
        run: |
          cd "$GITHUB_WORKSPACE"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          BASE_SHA=${{ github.event.pull_request.base.sha }}
          HEAD_SHA=${{ github.event.pull_request.head.sha }}

          # Capture and clean diff
          RAW_DIFF=$(git diff --unified=0 "$BASE_SHA" "$HEAD_SHA" | head -c 5450)
          CLEAN_DIFF=$(echo "$RAW_DIFF" | grep -vE '^diff --git|^index |^--- |^\+\+\+ |^@@ ')

          # Refined flat prompt (no INST tags)
          PROMPT="You're a senior AI code reviewer.
          Please summarize the following GitHub code changes.

          **Include**:
          - Purpose of this PR
          - Key technical changes
          - Any architectural or functional impact

          **Do NOT include**:
          - Raw code snippets
          - File paths
          - GitHub Actions workflow details

          Changes:
          $CLEAN_DIFF"

          MAIN_BIN="${{ steps.locate-cli.outputs.main-path }}"
          if [ ! -x "$MAIN_BIN" ]; then
            echo "‚ùå llama-cli binary not executable or missing at $MAIN_BIN"
            exit 1
          fi

          SUMMARY=$("$MAIN_BIN" \
            -m /models/mistral.gguf \
            --temp 0.7 \
            --ctx-size 2048 \
            --keep -1 \
            --n-predict 512 \
            --prompt "$PROMPT")

          # Format nicely
          echo "SUMMARY<<EOF" >> $GITHUB_OUTPUT
          echo -e "## üìù PR Summary by Local LLM\n\n$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "$SUMMARY"
      - name: Post summary
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ### ü§ñ Local LLM Analysis (Mistral 7B)

            ${{ steps.llm-summary.outputs.SUMMARY }}

            *Generated on GitHub Actions runner*
          edit-mode: replace
