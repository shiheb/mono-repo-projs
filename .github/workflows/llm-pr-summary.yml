name: Local LLM PR Summary

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: read
  pull-requests: write

jobs:
  generate-summary:
    runs-on: ubuntu-latest
    container:
      #image: ghcr.io/llama-cpp/llama-cpp:latest
      image: ghcr.io/ggerganov/llama.cpp:full
      #image: ghcr.io/ggerganov/llama.cpp:latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: Install wget
        run: |
          apt-get update && apt-get install -y wget
      - name: Download model (Mistral 7B)
        run: |
          wget https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf \
            -O /models/mistral.gguf

      - name: Generate diff summary
        id: llm-summary
        run: |
          # Get formatted diff
          DIFF_CONTENT=$(git diff --unified=1 ${{ github.event.pull_request.base.sha }}..${{ github.event.pull_request.head.sha }})

          # Create prompt
          PROMPT="[INST] Analyze these code changes for a pull request. \
          Focus on: 1) Main purpose, 2) Key changes, 3) Potential impacts. \
          Be concise but technical.\n\n${DIFF_CONTENT}[/INST]"

          # Run inference (4-bit quantized)
          SUMMARY=$(echo "$PROMPT" | llama.cpp \
            --model /models/mistral.gguf \
            --temp 0.7 \
            --ctx-size 2048 \
            --keep -1 \
            --n-predict 512)

          echo "SUMMARY<<EOF" >> $GITHUB_OUTPUT
          echo "$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Post summary
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ### ðŸ¤– Local LLM Analysis (Mistral 7B)

            ${{ steps.llm-summary.outputs.SUMMARY }}

            *Generated on GitHub Actions runner*
          edit-mode: replace
