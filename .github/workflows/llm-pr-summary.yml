name: Local LLM PR Summary

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: read
  pull-requests: write

jobs:
  generate-summary:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/ggml-org/llama.cpp:full

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install build dependencies
        run: |
          apt-get update && apt-get install -y cmake build-essential git libcurl4-openssl-dev

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggml-org/llama.cpp.git /llama.cpp

      - name: Build llama.cpp
        run: |
          cd /llama.cpp
          cmake -B build -DLLAMA_BUILD_EXAMPLES=ON
          cmake --build build --config Release -j$(nproc)

      - name: Download model (Mistral 7B)
        run: |
          mkdir -p /models/
          curl -L https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf \
            -o /models/mistral.gguf

      - name: Locate `llama-cli` binary
        id: locate-cli
        run: |
          CLI_PATH=$(find /llama.cpp/build -type f -name llama-cli -executable | head -n 1)
          echo "Found llama-cli binary at: $CLI_PATH"
          if [ -z "$CLI_PATH" ]; then
            echo "‚ùå llama-cli binary not found"
            exit 1
          fi
          echo "main-path=$CLI_PATH" >> $GITHUB_OUTPUT

      - name: Generate diff summary
        id: llm-summary
        run: |
          cd "$GITHUB_WORKSPACE"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"

          BASE_SHA=${{ github.event.pull_request.base.sha }}
          HEAD_SHA=${{ github.event.pull_request.head.sha }}

          # Get clean diff without metadata
          RAW_DIFF=$(git diff --unified=0 "$BASE_SHA" "$HEAD_SHA" | head -c 8000)
          CLEAN_DIFF=$(echo "$RAW_DIFF" | grep -vE '^diff --git|^index |^--- |^\+\+\+ |^@@ ' | grep -vE '^[-+]$' | grep -vE '^[-+]\s*$')

          PROMPT="You are an expert code reviewer analyzing a GitHub pull request. 
          Provide a concise technical summary (3-5 bullet points) focusing on:

          - The primary purpose of these changes
          - Key technical modifications (architecture, logic, dependencies)
          - Potential impact on the system

          Format requirements:
          - Maximum 200 words
          - No raw code snippets
          - No file paths
          - No workflow implementation details
          - No repeated information
          - Use clear, professional language

          Changes to analyze:
          $CLEAN_DIFF"

          MAIN_BIN="${{ steps.locate-cli.outputs.main-path }}"
          if [ ! -x "$MAIN_BIN" ]; then
            echo "‚ùå llama-cli binary not executable or missing at $MAIN_BIN"
            exit 1
          fi

          SUMMARY=$("$MAIN_BIN" \
            -m /models/mistral.gguf \
            -t 4 \
            --temp 0.5 \
            --ctx-size 2048 \
            --keep -1 \
            --n-predict 384 \
            --repeat-penalty 1.1 \
            --prompt "$PROMPT")

          {
            echo "SUMMARY<<EOF"
            echo "### ü§ñ LLM PR Analysis"
            echo "$SUMMARY" | grep -vE '^Main Purpose:|^Key Changes:|^Impact:' | head -n 8
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Post summary
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ### ü§ñ Concise PR Analysis

            ${{ steps.llm-summary.outputs.SUMMARY }}

            _AI-generated summary based on code changes_
          edit-mode: replace
