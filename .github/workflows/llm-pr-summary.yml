name: Local LLM PR Summary

on:
  pull_request:
    types: [opened, synchronize]

permissions:
  contents: read
  pull-requests: write

jobs:
  generate-summary:
    runs-on: ubuntu-latest
    container:
      image: ghcr.io/ggml-org/llama.cpp:full

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Install build dependencies
        run: |
          apt-get update && apt-get install -y cmake build-essential git libcurl4-openssl-dev

      - name: Clone llama.cpp
        run: |
          git clone https://github.com/ggml-org/llama.cpp.git /llama.cpp

      - name: Build llama.cpp
        run: |
          cd /llama.cpp
          cmake -B build -DLLAMA_BUILD_EXAMPLES=ON
          cmake --build build --config Release -j$(nproc)

      - name: Download model (Mistral 7B)
        run: |
          mkdir -p /models/
          curl -L https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/resolve/main/mistral-7b-instruct-v0.1.Q4_K_M.gguf \
            -o /models/mistral.gguf

      - name: Locate `llama-cli` binary
        id: locate-cli
        run: |
          echo "Listing all executables in build dir..."
          find /llama.cpp/build -type f -executable -exec ls -l {} \;

          CLI_PATH=$(find /llama.cpp/build -type f -name llama-cli -executable | head -n 1)
          echo "Found llama-cli binary at: $CLI_PATH"
          if [ -z "$CLI_PATH" ]; then
            echo "‚ùå llama-cli binary not found"
            exit 1
          fi
          echo "main-path=$CLI_PATH" >> $GITHUB_OUTPUT

      - name: Generate diff summary
        id: llm-summary
        run: |
          cd "$GITHUB_WORKSPACE"
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
          git status || { echo "‚ùå Not a git repo"; exit 1; }

          BASE_SHA=${{ github.event.pull_request.base.sha }}
          HEAD_SHA=${{ github.event.pull_request.head.sha }}

          # Get the diff and limit it to ~6000 characters (safe for ~2000 tokens)
          DIFF_CONTENT=$(git diff --unified=1 "$BASE_SHA" "$HEAD_SHA")
          MAX_CHARS=5500
          TRUNCATED_DIFF=$(echo "$DIFF_CONTENT" | head -c $MAX_CHARS)

          PROMPT="[INST] Analyze these code changes for a pull request. \
          Focus on: 1) Main purpose, 2) Key changes, 3) Potential impacts. \
          Be concise but technical.\n\n${TRUNCATED_DIFF}[/INST]"

          MAIN_BIN="${{ steps.locate-cli.outputs.main-path }}"
          if [ ! -x "$MAIN_BIN" ]; then
            echo "‚ùå llama-cli binary not executable or missing at $MAIN_BIN"
            exit 1
          fi

          SUMMARY=$("$MAIN_BIN" \
            -m /models/mistral.gguf \
            --temp 0.7 \
            --ctx-size 2048 \
            --keep -1 \
            --n-predict 512 \
            --prompt "$PROMPT")

          echo "SUMMARY<<EOF" >> $GITHUB_OUTPUT
          echo "$SUMMARY" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

          echo "$SUMMARY"

      - name: Post summary
        uses: peter-evans/create-or-update-comment@v4
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: |
            ### ü§ñ Local LLM Analysis (Mistral 7B)

            ${{ steps.llm-summary.outputs.SUMMARY }}

            *Generated on GitHub Actions runner*
          edit-mode: replace
